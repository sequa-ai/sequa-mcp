# Sequa MCP

> **The missing brain for your AI dev tools**

## ü§î What is Sequa?

Sequa is a **Contextual Knowledge Engine** that unifies code, documentation and tickets across *multiple* repositories and streams that live context to any LLM‚Äëpowered assistant. By giving tools like Cursor or Claude deep, always‚Äëcurrent project knowledge, Sequa helps them answer architecture‚Äëlevel questions, generate more accurate code and slash hallucinations.

## üñ•Ô∏è What is Sequa MCP?

`sequa‚Äëmcp` is a tiny proxy that lets any **STDIO‚Äëbased** AI client talk to your Sequa workspace using the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction). It forwards STDIO traffic to Sequa‚Äôs **streamable HTTP MCP endpoint** - so IDEs that only support the *command* transport can connect with **zero extra infrastructure**.

### Why not just use a URL?

Most IDEs currently speak MCP over STDIO **commands** and assume the proxy is responsible for networking. Sequa exposes an advanced bidirectional HTTP stream, not SSE, so direct `url:` configs will not work *yet*. Until IDEs add first‚Äëclass support, always configure Sequa through the **command/args** option shown below.

## üöÄ Quick Start

### Via NPX

```bash
npx -y @sequa-ai/sequa-mcp@latest  https://mcp.sequa.ai/<endpoint>
```

### Via Docker

```bash
docker run -i --rm --network host sequa/sequa-mcp:latest  https://mcp.sequa.ai/<endpoint>
```

---

## üîå Connect Your Favourite Tools

> Replace ` https://mcp.sequa.ai/<endpoint>` with your actual Sequa MCP URL. **Always** use the `command` style until IDEs support HTTP‚Äëstream URLs directly.

### Cursor

`~/.cursor/mcp.json`

```json
{
  "mcpServers": {
    "sequa": {
      "command": "npx",
      "args": [
        "-y",
        "@sequa-ai/sequa-mcp@latest",
        " https://mcp.sequa.ai/<endpoint>"
      ]
    }
  }
}
```

### Claude Desktop

Settings ‚ûú Developer ‚ûú **Edit Config**

```json
{
  "mcpServers": {
    "sequa": {
      "command": "npx",
      "args": [
        "-y",
        "@sequa-ai/sequa-mcp@latest",
        "https://mcp.sequa.ai/<endpoint>"
      ]
    }
  }
}
```

### Windsurf

`~/.codeium/windsurf/mcp_config.json`

```json
{
  "mcpServers": {
    "sequa": {
      "command": "npx",
      "args": [
        "-y",
        "@sequa-ai/sequa-mcp@latest",
        "https://mcp.sequa.ai/<endpoint>"
      ]
    }
  }
}
```

### VS Code

`.vscode/mcp.json`

```json
{
  "servers": {
    "sequa": {
      "command": "npx",
      "args": [
        "-y",
        "@sequa-ai/sequa-mcp@latest",
        "https://mcp.sequa.ai/<endpoint>"
      ]
    }
  }
}
```

### Cline (Claude Dev‚ÄëTools)

`~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json`

```json
{
  "mcpServers": {
    "sequa": {
      "command": "npx",
      "args": [
        "-y",
        "@sequa-ai/sequa-mcp@latest",
        "https://mcp.sequa.ai/<endpoint>"
      ],
      "disabled": false,
      "autoApprove": []
    }
  }
}
```

### Highlight AI

1. Click the plugins icon (@) ‚ûú **Installed Plugins** ‚ûú **Custom Plugin** ‚ûú **Add using a command**
2. Use:

   ```bash
   npx -y @sequa-ai/sequa-mcp@latest https://mcp.sequa.ai/<endpoint>
   ```

### Augment Code

```bash
npx @sequa-ai/sequa-mcp@latest https://mcp.sequa.ai/<endpoint>
```

Or in `augment_config.json`:

```json
{
  "mcpServers": {
    "sequa": {
      "command": "npx",
      "args": [
        "-y",
        "@sequa-ai/sequa-mcp@latest",
        "https://mcp.sequa.ai/<endpoint>"
      ]
    }
  }
}
```

---

## ‚öôÔ∏è How It Works

```text
IDE / Agent ‚áÑ Sequa MCP (local proxy) ‚áÑ Sequa Workspace (HTTP‚Äëstream MCP)
```

1. Your IDE writes MCP requests on STDIO.
2. `sequa‚Äëmcp` streams them over HTTPS to the Sequa workspace.
3. Sequa enriches the requests with real‚Äëtime, multi‚Äërepo context and streams back partial results.
4. The proxy pipes the bytes straight to your IDE for instant feedback.

